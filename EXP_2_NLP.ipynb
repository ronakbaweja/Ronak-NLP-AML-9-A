{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AHOq0BsgOAL",
        "outputId": "9373850e-a872-471b-b440-0bb569c41858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "read\n",
            "read\n",
            "bonjour\n",
            "eat\n",
            "read\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "stemming_word = PorterStemmer()\n",
        "stemming_word.stem('writing')\n",
        "stemming_word.stem('believe')\n",
        "\n",
        "# lancasterStemmer\n",
        "import nltk\n",
        "from nltk.stem import LancasterStemmer\n",
        "stemming_word_lan = LancasterStemmer()\n",
        "stemming_word_lan.stem('reads')\n",
        "stemming_word_lan.stem('sweets')\n",
        "stemming_word_lan.stem('reading')\n",
        "\n",
        "# RegexpStemmer\n",
        "import nltk\n",
        "from nltk.stem import RegexpStemmer\n",
        "import nltk\n",
        "from nltk.stem import RegexpStemmer\n",
        "stemming_word_reg=RegexpStemmer('ing')\n",
        "print(stemming_word_reg.stem('reading'))\n",
        "print(stemming_word_reg.stem('ingread'))\n",
        "#SnowballStemmer\n",
        "import nltk\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "snowball_stemmer = SnowballStemmer.languages\n",
        "lang_french = SnowballStemmer('french')\n",
        "print(lang_french.stem('bonjoura'))\n",
        "\n",
        "lang_english = SnowballStemmer('english')\n",
        "print(lang_english.stem('eating'))\n",
        "print(lang_english.stem('reading'))\n",
        "\n",
        "#Lemmatization\n",
        "#WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "ex_lemma = WordNetLemmatizer()\n",
        "\n",
        ""
      ]
    }
  ]
}